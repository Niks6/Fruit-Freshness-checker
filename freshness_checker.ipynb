{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjfu5lhMNcBw"
      },
      "source": [
        "Dataset Preparation: you have to break you data into train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKiNmgzUrSiE",
        "outputId": "c0d454f6-166e-4ed1-cd68-2fe0cf43033d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset split into train/validation/test at output_banana_dataset\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_images(\n",
        "    input_dir,\n",
        "    output_dir,\n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.15,\n",
        "    test_ratio=0.15,\n",
        "    seed=42\n",
        "):\n",
        "    assert round(train_ratio + val_ratio + test_ratio, 2) == 1.0, \"Ratios must sum to 1.0\"\n",
        "\n",
        "    class_names = os.listdir(input_dir)\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(input_dir, class_name)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(class_dir)\n",
        "        images = [img for img in images if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        train_imgs, temp_imgs = train_test_split(images, train_size=train_ratio, random_state=seed)\n",
        "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=test_ratio / (val_ratio + test_ratio), random_state=seed)\n",
        "\n",
        "        for split, split_imgs in zip(['train', 'validation', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
        "            split_class_dir = os.path.join(output_dir, split, class_name)\n",
        "            os.makedirs(split_class_dir, exist_ok=True)\n",
        "\n",
        "            for img in split_imgs:\n",
        "                src_path = os.path.join(class_dir, img)\n",
        "                dst_path = os.path.join(split_class_dir, img)\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "\n",
        "    print(f\"Dataset split into train/validation/test at {output_dir}\")\n",
        "\n",
        "split_images(\n",
        "    input_dir=\"banana_dataset\",        \n",
        "    output_dir=\"output_banana_dataset\",                \n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.15,\n",
        "    test_ratio=0.15\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9vDPtXBqe6-"
      },
      "source": [
        "Importing the pretrained model:\n",
        "you have to check your dataset with different model to get better result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17eFF3a-Nztw"
      },
      "source": [
        "ResNet50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_Ifq74Rphhu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) \n",
        "\n",
        "num_classes = 7 \n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zddM7V8N3NU"
      },
      "source": [
        "InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL_Dv6ccN5L9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "num_classes = 7 \n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) \n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x) \n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcSFdSf9OATH"
      },
      "source": [
        "MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKVtTK3yODOe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) \n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unGFOE_kqpGn"
      },
      "source": [
        "Model Training: you have to write this piece of code multiple time because each model accept the diffrent dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFQ1ARUWp6iE",
        "outputId": "75139d7c-e65b-445b-e2b4-103b7202802a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 895 images belonging to 7 classes.\n",
            "Found 189 images belonging to 7 classes.\n",
            "Found 196 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Data/fine_output_banana_dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' \n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Data/fine_output_banana_dataset/validation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Data/fine_output_banana_dataset/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6d49q_rPIiq",
        "outputId": "4ce3e7c8-b2bc-4a14-f931-0e6bc2dceddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 895 images belonging to 7 classes.\n",
            "Found 189 images belonging to 7 classes.\n",
            "Found 196 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Data/fine_output_banana_dataset/train',\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' \n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Data/fine_output_banana_dataset/validation',\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Data/fine_output_banana_dataset/test',\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False \n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFQGdN0Cqq95"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7OJpj09rp-BV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J_otWr6qurj"
      },
      "source": [
        "Training the model with the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6KGE5JIqA3O",
        "outputId": "09ef8f58-ab92-4408-fd7f-9357a48b0bee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.2699 - loss: 1.8238 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.57672, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 18s/step - accuracy: 0.2747 - loss: 1.8145 - val_accuracy: 0.5767 - val_loss: 1.1531\n",
            "Epoch 2/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - accuracy: 0.5879 - loss: 1.0951\n",
            "Epoch 2: val_accuracy improved from 0.57672 to 0.69841, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 910ms/step - accuracy: 0.5890 - loss: 1.0937 - val_accuracy: 0.6984 - val_loss: 0.9228\n",
            "Epoch 3/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - accuracy: 0.7235 - loss: 0.8912\n",
            "Epoch 3: val_accuracy improved from 0.69841 to 0.71429, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 917ms/step - accuracy: 0.7232 - loss: 0.8905 - val_accuracy: 0.7143 - val_loss: 0.8136\n",
            "Epoch 4/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.7391 - loss: 0.8141\n",
            "Epoch 4: val_accuracy improved from 0.71429 to 0.79365, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 922ms/step - accuracy: 0.7395 - loss: 0.8132 - val_accuracy: 0.7937 - val_loss: 0.7146\n",
            "Epoch 5/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860ms/step - accuracy: 0.8162 - loss: 0.6883\n",
            "Epoch 5: val_accuracy improved from 0.79365 to 0.83069, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 930ms/step - accuracy: 0.8154 - loss: 0.6884 - val_accuracy: 0.8307 - val_loss: 0.6408\n",
            "Epoch 6/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step - accuracy: 0.8292 - loss: 0.6190\n",
            "Epoch 6: val_accuracy did not improve from 0.83069\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 878ms/step - accuracy: 0.8288 - loss: 0.6194 - val_accuracy: 0.8201 - val_loss: 0.5917\n",
            "Epoch 7/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795ms/step - accuracy: 0.8183 - loss: 0.6109\n",
            "Epoch 7: val_accuracy improved from 0.83069 to 0.83598, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 879ms/step - accuracy: 0.8183 - loss: 0.6106 - val_accuracy: 0.8360 - val_loss: 0.5591\n",
            "Epoch 8/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785ms/step - accuracy: 0.8251 - loss: 0.5723\n",
            "Epoch 8: val_accuracy did not improve from 0.83598\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 821ms/step - accuracy: 0.8247 - loss: 0.5726 - val_accuracy: 0.8148 - val_loss: 0.5609\n",
            "Epoch 9/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8426 - loss: 0.5251\n",
            "Epoch 9: val_accuracy improved from 0.83598 to 0.84127, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 918ms/step - accuracy: 0.8426 - loss: 0.5252 - val_accuracy: 0.8413 - val_loss: 0.5045\n",
            "Epoch 10/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839ms/step - accuracy: 0.8470 - loss: 0.4992\n",
            "Epoch 10: val_accuracy improved from 0.84127 to 0.87831, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 907ms/step - accuracy: 0.8469 - loss: 0.4992 - val_accuracy: 0.8783 - val_loss: 0.4706\n",
            "Epoch 11/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.8575 - loss: 0.5099\n",
            "Epoch 11: val_accuracy improved from 0.87831 to 0.89947, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 926ms/step - accuracy: 0.8580 - loss: 0.5086 - val_accuracy: 0.8995 - val_loss: 0.4408\n",
            "Epoch 12/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8637 - loss: 0.4799\n",
            "Epoch 12: val_accuracy did not improve from 0.89947\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 884ms/step - accuracy: 0.8640 - loss: 0.4791 - val_accuracy: 0.8942 - val_loss: 0.4304\n",
            "Epoch 13/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789ms/step - accuracy: 0.8897 - loss: 0.4239\n",
            "Epoch 13: val_accuracy improved from 0.89947 to 0.90476, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 873ms/step - accuracy: 0.8893 - loss: 0.4241 - val_accuracy: 0.9048 - val_loss: 0.4270\n",
            "Epoch 14/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831ms/step - accuracy: 0.8495 - loss: 0.4656\n",
            "Epoch 14: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 876ms/step - accuracy: 0.8502 - loss: 0.4645 - val_accuracy: 0.8466 - val_loss: 0.4455\n",
            "Epoch 15/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.8558 - loss: 0.4450\n",
            "Epoch 15: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 879ms/step - accuracy: 0.8557 - loss: 0.4450 - val_accuracy: 0.9048 - val_loss: 0.3993\n",
            "Epoch 16/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8890 - loss: 0.3749\n",
            "Epoch 16: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 904ms/step - accuracy: 0.8888 - loss: 0.3754 - val_accuracy: 0.8942 - val_loss: 0.3775\n",
            "Epoch 17/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.8943 - loss: 0.3606\n",
            "Epoch 17: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 873ms/step - accuracy: 0.8942 - loss: 0.3609 - val_accuracy: 0.8942 - val_loss: 0.3675\n",
            "Epoch 18/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792ms/step - accuracy: 0.8960 - loss: 0.3628\n",
            "Epoch 18: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 846ms/step - accuracy: 0.8955 - loss: 0.3635 - val_accuracy: 0.8889 - val_loss: 0.3559\n",
            "Epoch 19/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.8771 - loss: 0.3884\n",
            "Epoch 19: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 809ms/step - accuracy: 0.8775 - loss: 0.3878 - val_accuracy: 0.8942 - val_loss: 0.3547\n",
            "Epoch 20/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813ms/step - accuracy: 0.8879 - loss: 0.3639\n",
            "Epoch 20: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 850ms/step - accuracy: 0.8879 - loss: 0.3640 - val_accuracy: 0.8836 - val_loss: 0.3663\n",
            "Epoch 21/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 0.8892 - loss: 0.3621\n",
            "Epoch 21: val_accuracy improved from 0.90476 to 0.92593, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 894ms/step - accuracy: 0.8889 - loss: 0.3617 - val_accuracy: 0.9259 - val_loss: 0.3134\n",
            "Epoch 22/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step - accuracy: 0.9041 - loss: 0.3214\n",
            "Epoch 22: val_accuracy did not improve from 0.92593\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 874ms/step - accuracy: 0.9040 - loss: 0.3217 - val_accuracy: 0.9206 - val_loss: 0.3095\n",
            "Epoch 23/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.9094 - loss: 0.3239\n",
            "Epoch 23: val_accuracy improved from 0.92593 to 0.93651, saving model to best_banana_freshness_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 903ms/step - accuracy: 0.9096 - loss: 0.3236 - val_accuracy: 0.9365 - val_loss: 0.3111\n",
            "Epoch 24/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - accuracy: 0.8997 - loss: 0.3457\n",
            "Epoch 24: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 837ms/step - accuracy: 0.8996 - loss: 0.3457 - val_accuracy: 0.9206 - val_loss: 0.2927\n",
            "Epoch 25/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - accuracy: 0.8973 - loss: 0.3348\n",
            "Epoch 25: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 850ms/step - accuracy: 0.8973 - loss: 0.3350 - val_accuracy: 0.9153 - val_loss: 0.3080\n",
            "Epoch 26/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769ms/step - accuracy: 0.8854 - loss: 0.3443\n",
            "Epoch 26: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 823ms/step - accuracy: 0.8858 - loss: 0.3436 - val_accuracy: 0.9365 - val_loss: 0.2877\n",
            "Epoch 27/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - accuracy: 0.9172 - loss: 0.3351\n",
            "Epoch 27: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 855ms/step - accuracy: 0.9171 - loss: 0.3346 - val_accuracy: 0.9312 - val_loss: 0.2831\n",
            "Epoch 28/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - accuracy: 0.9125 - loss: 0.3014\n",
            "Epoch 28: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 811ms/step - accuracy: 0.9123 - loss: 0.3016 - val_accuracy: 0.9312 - val_loss: 0.2726\n",
            "Epoch 29/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.8996 - loss: 0.3148\n",
            "Epoch 29: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 812ms/step - accuracy: 0.9000 - loss: 0.3146 - val_accuracy: 0.9312 - val_loss: 0.2650\n",
            "Epoch 30/30\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step - accuracy: 0.9036 - loss: 0.2930\n",
            "Epoch 30: val_accuracy did not improve from 0.93651\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 845ms/step - accuracy: 0.9038 - loss: 0.2929 - val_accuracy: 0.9312 - val_loss: 0.2637\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_banana_freshness_model.h5',\n",
        "                                   monitor='val_accuracy',\n",
        "                                   save_best_only=True,\n",
        "                                   mode='max',\n",
        "                                   verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYrVLl-5q0cE"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op0ZWTkzqIGo",
        "outputId": "357b64dd-447e-4eeb-e6bb-b3f02d48827a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 15s/step - accuracy: 0.8999 - loss: 0.3131\n",
            "Test Loss: 0.2619\n",
            "Test Accuracy: 0.9133\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5YY4J5nq9sw"
      },
      "source": [
        "Getting the detailed metrics of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIk8A3eKqSio",
        "outputId": "d805ed80-2f0a-4d76-9afe-cf15cc845792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 729ms/step\n",
            "Confusion Matrix:\n",
            "[[ 0 24  0  0  4  0  0]\n",
            " [ 0 22  0  0  6  0  0]\n",
            " [ 0 17  0  0 11  0  0]\n",
            " [ 1  3  0  0 24  0  0]\n",
            " [ 0  3  0  0 19  0  6]\n",
            " [ 0  1  0  0  8  0 19]\n",
            " [ 0  0  0  0  3  0 25]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "1_days_older       0.00      0.00      0.00        28\n",
            "2_days_older       0.31      0.79      0.45        28\n",
            "3_days_older       0.00      0.00      0.00        28\n",
            "4_days_older       0.00      0.00      0.00        28\n",
            "5_days_older       0.25      0.68      0.37        28\n",
            "6_days_older       0.00      0.00      0.00        28\n",
            "7_days_older       0.50      0.89      0.64        28\n",
            "\n",
            "    accuracy                           0.34       196\n",
            "   macro avg       0.15      0.34      0.21       196\n",
            "weighted avg       0.15      0.34      0.21       196\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "test_labels = test_generator.classes\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "idx_to_class = {v: k for k, v in train_generator.class_indices.items()}\n",
        "sorted_class_names = [idx_to_class[i] for i in sorted(idx_to_class.keys())]\n",
        "\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, predicted_classes))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, predicted_classes, target_names=sorted_class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHX50J6irCQ6"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzO2Z-GYqU80",
        "outputId": "d3320144-5bee-4f2a-de74-be17fd34e328"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('final_banana_freshness_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNrJKgMJrEJy"
      },
      "source": [
        "Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is7joHUgqW_T",
        "outputId": "f0db7636-be58-4a2b-9a2a-96118001f0b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('best_banana_freshness_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmonMgbbrHkF"
      },
      "source": [
        "Predicting using the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWzv6fjaqaiA",
        "outputId": "cca7a82a-0f9e-4956-b055-d7284f68d6a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33s/step\n",
            "The banana is predicted to be: 2_days_older with 52.42% confidence.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def predict_freshness(image_path, model, class_names):\n",
        "    img = image.load_img(image_path, target_size=(299, 299))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) \n",
        "    img_array /= 255.0 \n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    predicted_freshness = class_names[predicted_class_index]\n",
        "    confidence = predictions[0][predicted_class_index]\n",
        "\n",
        "    return predicted_freshness, confidence\n",
        "\n",
        "class_names_list = list(train_generator.class_indices.keys())\n",
        "idx_to_class_map = {v: k for k, v in train_generator.class_indices.items()}\n",
        "sorted_class_names_for_prediction = [idx_to_class_map[i] for i in sorted(idx_to_class_map.keys())]\n",
        "\n",
        "\n",
        "image_to_predict = '/content/Screenshot 2025-07-17 031004.png'\n",
        "freshness, confidence = predict_freshness(image_to_predict, loaded_model, sorted_class_names_for_prediction)\n",
        "\n",
        "print(f\"The banana is predicted to be: {freshness} with {confidence*100:.2f}% confidence.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "448ef494"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8af3a360"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
